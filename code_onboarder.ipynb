{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Phase 1: Introduction\n",
    "\n",
    "## 1.1 Background\n",
    "Open-source software (OSS) is the backbone of modern technology, driving innovation through community collaboration. A healthy open-source project relies on a continuous influx of new contributors to fix bugs, add features, and maintain the codebase. However, diving into an unfamiliar, complex repository is one of the most daunting tasks for any developer, whether they are junior programmers or seasoned veterans.\n",
    "\n",
    "## 1.2 Problem Statement\n",
    "Despite the desire to contribute to open-source, developers face a massive barrier to entry: **onboarding friction**. New contributors are often confronted with massive codebases, fragmented or outdated documentation, and complex architectural dependencies.\n",
    "\n",
    "Currently, a developer looking to contribute must spend hours or even days manually reading code, tracing functions, and deciphering the project's structure before writing a single line of code. This steep learning curve leads to developer frustration, abandoned pull requests, and a significant loss of potential talent for the open-source community.\n",
    "\n",
    "## 1.3 Solution & Approach\n",
    "To eliminate this onboarding friction, I'm building **CodeBuddy**, an AI-powered Open-Source Onboarder. CodeBuddy acts as an intelligent companion that guides developers through new codebases, explaining architecture, locating specific logic, and answering questions in real-time.\n",
    "\n",
    "***For assignment perspective I'm using local tech stack cannot ingest large repository yet. Once I'm able to mature it as agent running in a dedicated GPU can ingest large reposiroty***\n",
    "\n",
    "### Our Approach:\n",
    "I will tackle this problem by building a Retrieval-Augmented Generation (RAG) pipeline tailored for source code:\n",
    "1. **Data Ingestion & Parsing:** I will ingest the target open-source repository (code files, READMEs, and existing documentation) and parse the codebase into meaningful, logical chunks (e.g., functions, classes, and modules).\n",
    "2. **Embedding & Indexing:** These code chunks will be converted into vector embeddings and stored in a vector database, allowing for fast, semantic search capabilities.\n",
    "3. **Retrieval & Generation:** When a user asks a question (e.g., *\"Where is the database connection handled?\"* or *\"Explain how the authentication middleware works\"*), the system will retrieve the most relevant code snippets and pass them to an LLM to generate a clear, context-aware explanation.\n",
    "\n",
    "### Why Use Large Language Models (LLMs)?\n",
    "Using an LLM is the cornerstone of CodeBuddy because traditional search tools (like `grep` or IDE text search) are vastly insufficient for true code comprehension. I need LLMs for the following reasons:\n",
    "* **Semantic Code Understanding:** LLMs go beyond keyword matching; they understand the *intent* and logic behind the code, allowing them to explain complex algorithms in plain English.\n",
    "* **Contextual Synthesis:** An LLM can look at multiple retrieved files simultaneously and synthesize an answer that explains how different components of the repository interact with each other.\n",
    "* **Interactive Guidance:** LLMs allow developers to have a dynamic, conversational back-and-forth. If a developer doesn't understand an initial explanation, they can ask the LLM to simplify it, provide an example, or trace a specific variable's journey through the codebase."
   ],
   "id": "63680e85fca2e91d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Phase 2: System Design\n",
    "\n",
    "In this phase, we design the architecture of CodeBuddy. We will break this down step-by-step, starting with how the user interacts with the system and how the AI interprets their needs.\n",
    "\n",
    "## 2.1 Conversation Initialization & Intent Handling\n",
    "\n",
    "Before CodeBuddy can search the repository or explain code, it needs to establish a structured conversation with the user and accurately understand their goals. This interaction layer acts as the front door to our system.\n",
    "\n",
    "### Step 1: Start a Conversation (LLM Initialization)\n",
    "To initiate the conversation, we must instantiate the LLM with a specific \"System Prompt\" and memory management. This ensures the model behaves like an expert developer rather than a generic chatbot.\n",
    "\n",
    "* **System Prompting:** We define the LLM's persona, constraints, and instructions. For example: *\"You are CodeBuddy, an expert senior engineer. Your goal is to help a junior developer onboard onto a new open-source repository. Be concise, reference specific file paths when known, and do not make up code that does not exist.\"*\n",
    "* **Session Memory:** Because onboarding requires continuous dialogue, we must initialize a chat memory object (e.g., using LangChain's `ConversationBufferMemory`). This allows the LLM to remember previous questions and maintain context throughout the session.\n",
    "\n",
    "### Step 2: Get User Input (Intent Clarity & Confirmation)\n",
    "When a developer types a question, open-source repositories are often too large to simply search blindly. We need an intent routing mechanism to ensure we are retrieving the right kind of information.\n",
    "\n",
    "* **Capturing Input:** The system receives the user's raw query (e.g., *\"How do I start this?\"* or *\"Where is the auth logic?\"*).\n",
    "* **Intent Clarity (Classification):** Before querying our vector database, we pass the raw input through a lightweight LLM call (or a dedicated classifier) to determine the *intent* of the question. Common intents for CodeBuddy might include:\n",
    "    * `PROJECT_SETUP`: Questions about installation, Docker, or `npm install`.\n",
    "    * `ARCHITECTURE_OVERVIEW`: High-level questions about how services interact.\n",
    "    * `CODE_EXPLANATION`: Deep dives into specific functions or files.\n",
    "    * `CONTRIBUTION_GUIDELINES`: Questions about how to submit a PR or run tests.\n",
    "* **Intent Confirmation:** If a user's query is highly ambiguous (e.g., *\"Explain the user stuff\"*), the system pauses. Instead of running an expensive and likely inaccurate search, CodeBuddy replies with an **Intent Confirmation** prompt: *\"It sounds like you want to know about User Authentication and Authorization. Is that correct, or are you looking for the User UI components?\"* This human-in-the-loop step ensures high-accuracy retrieval later in the pipeline."
   ],
   "id": "e2d3a0222dc330fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.1.1 Implementation: Initialization and Intent Routing (Local Model)\n",
    "\n",
    "In the code block below, we set up the conversational interface entirely on our local machine. This ensures that repository code and developer queries remain completely private.\n",
    "\n",
    "\n",
    "\n",
    "This implementation handles:\n",
    "1. **Local LLM Setup:** We initialize a local model (e.g., `llama3.1` or `mistral`) using Ollama. We set the `format=\"json\"` parameter to guarantee the model outputs strictly parsable JSON for our routing logic.\n",
    "2. **Memory:** We instantiate a `ConversationBufferMemory` to keep track of the chat history.\n",
    "3. **Intent Classifier:** We define a specific prompt that forces the LLM to analyze the user's input and categorize it, outputting the result, a confidence score, and any clarifying questions."
   ],
   "id": "90f1c535cd18e05e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:04:04.856395Z",
     "start_time": "2026-02-21T11:04:01.064836Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install langchain langchain-ollama",
   "id": "42d8545119d0a39e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\r\n",
      "  Downloading langchain-1.2.10-py3-none-any.whl.metadata (5.7 kB)\r\n",
      "Collecting langchain-ollama\r\n",
      "  Downloading langchain_ollama-1.0.1-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting langchain-core<2.0.0,>=1.2.10 (from langchain)\r\n",
      "  Downloading langchain_core-1.2.14-py3-none-any.whl.metadata (4.4 kB)\r\n",
      "Collecting langgraph<1.1.0,>=1.0.8 (from langchain)\r\n",
      "  Downloading langgraph-1.0.9-py3-none-any.whl.metadata (7.4 kB)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain) (2.10.3)\r\n",
      "Collecting ollama<1.0.0,>=0.6.0 (from langchain-ollama)\r\n",
      "  Downloading ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (1.33)\r\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.2.10->langchain)\r\n",
      "  Downloading langsmith-0.7.6-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: packaging>=23.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (24.2)\r\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core<2.0.0,>=1.2.10->langchain)\r\n",
      "  Downloading pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.4 kB)\r\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.2.10->langchain)\r\n",
      "  Downloading tenacity-9.1.4-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (4.12.2)\r\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core<2.0.0,>=1.2.10->langchain)\r\n",
      "  Downloading uuid_utils-0.14.1-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (4.8 kB)\r\n",
      "Collecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.8->langchain)\r\n",
      "  Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.8 (from langgraph<1.1.0,>=1.0.8->langchain)\r\n",
      "  Downloading langgraph_prebuilt-1.0.8-py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph<1.1.0,>=1.0.8->langchain)\r\n",
      "  Downloading langgraph_sdk-0.3.8-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.8->langchain)\r\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: httpx>=0.27 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ollama<1.0.0,>=0.6.0->langchain-ollama) (0.28.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\r\n",
      "Requirement already satisfied: anyio in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (4.12.1)\r\n",
      "Requirement already satisfied: certifi in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (2025.4.26)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (3.7)\r\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (0.16.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/jags/miniconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain) (2.1)\r\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain)\r\n",
      "  Downloading ormsgpack-1.12.2-cp313-cp313-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (3.2 kB)\r\n",
      "Collecting orjson>=3.11.5 (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain)\r\n",
      "  Downloading orjson-3.11.7-cp313-cp313-macosx_15_0_arm64.whl.metadata (41 kB)\r\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain)\r\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (2.32.3)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (0.23.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (2.3.0)\r\n",
      "Downloading langchain-1.2.10-py3-none-any.whl (111 kB)\r\n",
      "Downloading langchain_ollama-1.0.1-py3-none-any.whl (29 kB)\r\n",
      "Downloading langchain_core-1.2.14-py3-none-any.whl (501 kB)\r\n",
      "Downloading langgraph-1.0.9-py3-none-any.whl (158 kB)\r\n",
      "Downloading ollama-0.6.1-py3-none-any.whl (14 kB)\r\n",
      "Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl (46 kB)\r\n",
      "Downloading langgraph_prebuilt-1.0.8-py3-none-any.whl (35 kB)\r\n",
      "Downloading langgraph_sdk-0.3.8-py3-none-any.whl (90 kB)\r\n",
      "Downloading langsmith-0.7.6-py3-none-any.whl (325 kB)\r\n",
      "Downloading pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\r\n",
      "Downloading tenacity-9.1.4-py3-none-any.whl (28 kB)\r\n",
      "Downloading uuid_utils-0.14.1-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (604 kB)\r\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m604.7/604.7 kB\u001B[0m \u001B[31m28.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\r\n",
      "Downloading orjson-3.11.7-cp313-cp313-macosx_15_0_arm64.whl (125 kB)\r\n",
      "Downloading ormsgpack-1.12.2-cp313-cp313-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (378 kB)\r\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\r\n",
      "Installing collected packages: xxhash, uuid-utils, tenacity, pyyaml, ormsgpack, orjson, requests-toolbelt, ollama, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-ollama, langgraph-prebuilt, langgraph, langchain\r\n",
      "Successfully installed langchain-1.2.10 langchain-core-1.2.14 langchain-ollama-1.0.1 langgraph-1.0.9 langgraph-checkpoint-4.0.0 langgraph-prebuilt-1.0.8 langgraph-sdk-0.3.8 langsmith-0.7.6 ollama-0.6.1 orjson-3.11.7 ormsgpack-1.12.2 pyyaml-6.0.3 requests-toolbelt-1.0.0 tenacity-9.1.4 uuid-utils-0.14.1 xxhash-3.6.0\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:05:40.619768Z",
     "start_time": "2026-02-21T11:05:40.559993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.memory import ConversationBufferMemory"
   ],
   "id": "908d9a487f0b4220",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T15:25:48.660679Z",
     "start_time": "2026-02-21T15:25:42.578846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0.2,\n",
    "    format=\"json\"\n",
    ")\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "intent_template = \"\"\"\n",
    "You are the routing engine for CodeBuddy, an AI assistant helping developers onboard onto an open-source codebase.\n",
    "Analyze the user's input and classify their intent into EXACTLY ONE of the following categories:\n",
    "- PROJECT_SETUP: Questions about installation, dependencies, Docker, etc.\n",
    "- ARCHITECTURE_OVERVIEW: Questions about folder structure, data flow, and architecture.\n",
    "- CODE_EXPLANATION: Questions about specific files, functions, or localized logic.\n",
    "- AMBIGUOUS: The request is too vague to search the codebase effectively.\n",
    "\n",
    "User Input: {user_input}\n",
    "\n",
    "Respond strictly in valid JSON format with the following schema:\n",
    "{{\n",
    "  \"intent\": \"CATEGORY\",\n",
    "  \"confidence\": 0.95,\n",
    "  \"clarifying_question\": \"Ask a question here ONLY if the intent is AMBIGUOUS, otherwise leave blank\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "intent_prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    template=intent_template\n",
    ")\n",
    "\n",
    "def process_user_input(user_query):\n",
    "    print(f\"User: {user_query}\")\n",
    "\n",
    "    formatted_prompt = intent_prompt.format(user_input=user_query)\n",
    "\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "\n",
    "    try:\n",
    "        raw_text = response.content if hasattr(response, \"content\") else response\n",
    "        classification = json.loads(raw_text)\n",
    "        intent = classification.get(\"intent\")\n",
    "        confidence = float(classification.get(\"confidence\", 0))\n",
    "\n",
    "        print(f\"[System Log] Intent Detected: {intent} (Confidence: {confidence})\")\n",
    "\n",
    "        if intent == \"AMBIGUOUS\" or confidence < 0.7:\n",
    "            clarification = classification.get(\"clarifying_question\", \"Could you please clarify what part of the project you are asking about?\")\n",
    "            print(f\"CodeBuddy: {clarification}\")\n",
    "            return None\n",
    "\n",
    "        return intent\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"[System Log] Error parsing intent. Asking user for clarification.\")\n",
    "        return \"AMBIGUOUS\"\n",
    "\n",
    "print(\"--- Test 1: Clear Intent ---\")\n",
    "intent_1 = process_user_input(\"How do I spin up the local Postgres database using Docker?\")\n",
    "\n",
    "print(\"\\n--- Test 2: Ambiguous Intent ---\")\n",
    "intent_2 = process_user_input(\"Explain the user stuff to me.\")"
   ],
   "id": "2629b5863933fddb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test 1: Clear Intent ---\n",
      "User: How do I spin up the local Postgres database using Docker?\n",
      "[System Log] Intent Detected: PROJECT_SETUP (Confidence: 0.95)\n",
      "\n",
      "--- Test 2: Ambiguous Intent ---\n",
      "User: Explain the user stuff to me.\n",
      "[System Log] Intent Detected: AMBIGUOUS (Confidence: 0.8)\n",
      "CodeBuddy: Can you please specify what 'user stuff' refers to? Are you asking about a particular file or functionality?\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2 Dynamic GitHub Ingestion and Vector Database\n",
    "\n",
    "For CodeBuddy to answer questions about a repository, it first needs to \"read\" and index the code. Instead of relying on local files, our system will prompt the user for a live GitHub URL and pull the code dynamically.\n",
    "\n",
    "\n",
    "This phase consists of three main steps:\n",
    "1. **Dynamic Loading:** We use Python's `input()` to grab the repository URL. Then, LangChain's `GitLoader` automatically clones it and loads its text files into memory.\n",
    "2. **Chunking (Code-Aware):** We split the files into smaller chunks using a Python-specific text splitter to ensure we don't accidentally slice functions or classes in half.\n",
    "3. **Embedding & Storage (ChromaDB):** We convert these text chunks into high-dimensional vector representations (embeddings) using our local Ollama model and store them in **Chroma** for semantic searching."
   ],
   "id": "b8313859e648cbd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T14:14:23.789605Z",
     "start_time": "2026-02-21T14:14:22.364871Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install GitPython chromadb langchain-community langchain-ollama",
   "id": "3e41cacbe588a826",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GitPython\r\n",
      "  Downloading gitpython-3.1.46-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: chromadb in /Users/jags/miniconda3/lib/python3.13/site-packages (1.5.1)\r\n",
      "Requirement already satisfied: langchain-community in /Users/jags/miniconda3/lib/python3.13/site-packages (0.4.1)\r\n",
      "Requirement already satisfied: langchain-ollama in /Users/jags/miniconda3/lib/python3.13/site-packages (1.0.1)\r\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython)\r\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.4.0)\r\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (2.10.3)\r\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.4.3)\r\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/jags/miniconda3/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.41.0)\r\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (2.3.3)\r\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (5.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (4.12.2)\r\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.24.2)\r\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (0.22.2)\r\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (0.51.1)\r\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (4.67.1)\r\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (7.7.0)\r\n",
      "Requirement already satisfied: importlib-resources in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (6.5.2)\r\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.78.1)\r\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (5.0.0)\r\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (0.24.0)\r\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (35.0.0)\r\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (9.1.4)\r\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (6.0.3)\r\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (5.2.0)\r\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (3.11.7)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (0.28.1)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (13.9.4)\r\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (4.26.0)\r\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (1.2.14)\r\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (1.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (2.0.46)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (2.32.5)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (3.13.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (0.6.7)\r\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (2.13.1)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (0.7.6)\r\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (0.4.3)\r\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-ollama) (0.6.1)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\r\n",
      "Requirement already satisfied: packaging>=24.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (24.2)\r\n",
      "Requirement already satisfied: pyproject_hooks in /Users/jags/miniconda3/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (1.2.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\r\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython)\r\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: anyio in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (4.12.1)\r\n",
      "Requirement already satisfied: certifi in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (3.7)\r\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/jags/miniconda3/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/jags/miniconda3/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\r\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/jags/miniconda3/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\r\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\r\n",
      "Requirement already satisfied: requests-oauthlib in /Users/jags/miniconda3/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\r\n",
      "Requirement already satisfied: urllib3!=2.6.0,>=1.24.2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\r\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/jags/miniconda3/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\r\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\r\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (0.14.1)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\r\n",
      "Requirement already satisfied: xxhash>=3.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.6.0)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\r\n",
      "Requirement already satisfied: flatbuffers in /Users/jags/miniconda3/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\r\n",
      "Requirement already satisfied: protobuf in /Users/jags/miniconda3/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.5)\r\n",
      "Requirement already satisfied: sympy in /Users/jags/miniconda3/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\r\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/jags/miniconda3/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\r\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\r\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (2.27.1)\r\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.3.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (2.2.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\r\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /Users/jags/miniconda3/lib/python3.13/site-packages (from tokenizers>=0.13.2->chromadb) (1.4.1)\r\n",
      "Requirement already satisfied: click>=8.2.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (8.3.1)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\r\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (0.0.4)\r\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/jags/miniconda3/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\r\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\r\n",
      "Requirement already satisfied: watchfiles>=0.20 in /Users/jags/miniconda3/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/jags/miniconda3/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (16.0)\r\n",
      "Requirement already satisfied: filelock in /Users/jags/miniconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.24.3)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2026.2.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\r\n",
      "Requirement already satisfied: typer-slim in /Users/jags/miniconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (0.24.0)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/jags/miniconda3/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/jags/miniconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (2.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\r\n",
      "Downloading gitpython-3.1.46-py3-none-any.whl (208 kB)\r\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\r\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\r\n",
      "Installing collected packages: smmap, gitdb, GitPython\r\n",
      "Successfully installed GitPython-3.1.46 gitdb-4.0.12 smmap-5.0.2\r\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T14:14:28.878213Z",
     "start_time": "2026-02-21T14:14:28.021532Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -U langchain-ollama",
   "id": "d1c84a1fd7b39c72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in /Users/jags/miniconda3/lib/python3.13/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-ollama) (1.2.14)\r\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-ollama) (0.6.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.33)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.7.6)\r\n",
      "Requirement already satisfied: packaging>=23.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (24.2)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.10.3)\r\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (6.0.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (9.1.4)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (4.12.2)\r\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.14.1)\r\n",
      "Requirement already satisfied: httpx>=0.27 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ollama<1.0.0,>=0.6.0->langchain-ollama) (0.28.1)\r\n",
      "Requirement already satisfied: anyio in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (4.12.1)\r\n",
      "Requirement already satisfied: certifi in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (2025.4.26)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (3.7)\r\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (0.16.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/jags/miniconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.1)\r\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.11.7)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.0.0)\r\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.32.5)\r\n",
      "Requirement already satisfied: xxhash>=3.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.6.0)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.23.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.27.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.3.0)\r\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T16:46:40.180096Z",
     "start_time": "2026-02-21T16:46:40.175185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "from langchain_community.document_loaders import GitLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, Language\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import chromadb\n",
    "import chromadb.config"
   ],
   "id": "55927fd99c34f247",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T16:46:58.338050Z",
     "start_time": "2026-02-21T16:46:43.301597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"=\"*50)\n",
    "print(\"üì• CodeBuddy Repository Ingestion\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "GITHUB_URL = input(\"Enter the GitHub Repository URL to ingest (e.g., https://github.com/hwchase17/langchain-tiny): \").strip()\n",
    "\n",
    "if not GITHUB_URL:\n",
    "    GITHUB_URL = \"https://github.com/bhagirathbhard/langchain-reporead\"\n",
    "    print(f\"\\n[System Log] No URL provided. Defaulting to: {GITHUB_URL}\")\n",
    "\n",
    "REPO_DESTINATION = \"./cloned_repo\"\n",
    "DB_DIR = \"./chroma_db\"\n",
    "\n",
    "if os.path.exists(REPO_DESTINATION):\n",
    "    print(f\"\\n[System Log] Clearing previous repository data at {REPO_DESTINATION}...\")\n",
    "    shutil.rmtree(REPO_DESTINATION)\n",
    "\n",
    "\n",
    "print(f\"\\n[System Log] Cloning and loading documents from {GITHUB_URL}...\")\n",
    "\n",
    "loader = GitLoader(\n",
    "    clone_url=GITHUB_URL,\n",
    "    repo_path=REPO_DESTINATION,\n",
    "    branch=\"main\",\n",
    "    file_filter=lambda file_path: file_path.endswith(\".py\") or file_path.endswith(\".md\")\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"[System Log] Successfully loaded {len(documents)} file(s) from GitHub.\")\n",
    "\n",
    "print(\"\\n[System Log] Splitting code into semantic chunks...\")\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "chunks = python_splitter.split_documents(documents)\n",
    "print(f\"[System Log] Created {len(chunks)} chunk(s).\")\n",
    "\n",
    "print(\"\\n[System Log] Generating embeddings and storing in local ChromaDB...\")\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.1\")\n",
    "\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=DB_DIR\n",
    ")\n",
    "\n",
    "print(\"\\n[System Log] ‚úÖ GitHub Ingestion complete! CodeBuddy's knowledge base is ready.\")"
   ],
   "id": "5c8ad7c5b6c2071b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üì• CodeBuddy Repository Ingestion\n",
      "==================================================\n",
      "\n",
      "[System Log] Clearing previous repository data at ./cloned_repo...\n",
      "\n",
      "[System Log] Cloning and loading documents from https://github.com/bhagirathbhard/langchain-reporead...\n",
      "[System Log] Successfully loaded 1 file(s) from GitHub.\n",
      "\n",
      "[System Log] Splitting code into semantic chunks...\n",
      "[System Log] Created 4 chunk(s).\n",
      "\n",
      "[System Log] Generating embeddings and storing in local ChromaDB...\n",
      "\n",
      "[System Log] ‚úÖ GitHub Ingestion complete! CodeBuddy's knowledge base is ready.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.3 Retrieval and Answer Generation\n",
    "\n",
    "The final step in our RAG pipeline is taking the user's question, finding the relevant code we just pulled from GitHub, and letting the LLM explain it.\n",
    "\n",
    "[Image of a Retrieval-Augmented Generation system querying a vector database]\n",
    "\n",
    "This phase works by chaining together a few core components:\n",
    "1. **The Retriever:** We convert our ChromaDB into a \"Retriever\" object. When given a query, it will search the database and return the top `k` most semantically similar code chunks from the GitHub repository.\n",
    "2. **The Prompt Template:** We define CodeBuddy's persona and provide a strict instruction to *only* use the retrieved context to answer the question, preventing the model from hallucinating code that doesn't exist.\n",
    "3. **The Document Chain (`create_stuff_documents_chain`):** This LangChain utility takes the retrieved code chunks and \"stuffs\" them into the `{context}` variable of our prompt.\n",
    "4. **The Retrieval Chain (`create_retrieval_chain`):** This acts as the orchestrator. It takes the user's input, hits the retriever, passes the documents to the document chain, and returns the final LLM-generated answer."
   ],
   "id": "8417833e8c937847"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T14:17:22.604956Z",
     "start_time": "2026-02-21T14:17:22.590775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n"
   ],
   "id": "c0dfa1b0c42dabfb",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T14:17:26.532556Z",
     "start_time": "2026-02-21T14:17:23.892498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = OllamaLLM(model=\"llama3.1\", temperature=0.3)\n",
    "\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are CodeBuddy, an expert senior engineer helping a junior developer onboard onto a new open-source codebase. \"\n",
    "    \"Use the following pieces of retrieved code context to answer the user's question. \"\n",
    "    \"If you don't know the answer or the context doesn't contain the right code, just clearly say that you don't know. \"\n",
    "    \"Do not make up code or file names. Keep your explanations clear, concise, and structured.\\n\\n\"\n",
    "    \"Context:\\n{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "print(\"--- Testing CodeBuddy Answer Generation ---\")\n",
    "\n",
    "test_question = \"Based on the repository, what is the main purpose of this project?\"\n",
    "print(f\"User: {test_question}\\n\")\n",
    "\n",
    "response = rag_chain.invoke({\"input\": test_question})\n",
    "\n",
    "print(\"CodeBuddy:\")\n",
    "print(response[\"answer\"])\n",
    "\n",
    "print(\"\\n---\")\n",
    "print(f\"[System Log] Answer generated using {len(response['context'])} retrieved source chunks.\")"
   ],
   "id": "ae14bd4f66cfa6c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing CodeBuddy Answer Generation ---\n",
      "User: Based on the repository, what is the main purpose of this project?\n",
      "\n",
      "CodeBuddy:\n",
      "The main purpose of this project is to provide a set of tools and scripts that leverage Langchain and OpenAI to read and analyze the content of a repository. It allows users to ask questions about a repository by storing them in a `questions.txt` file, and then generates individual answers in markdown files within an `answers` folder using the output from the LLM (Large Language Model).\n",
      "\n",
      "---\n",
      "[System Log] Answer generated using 4 retrieved source chunks.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Phase 3: Bringing it all together (The Chat Loop)\n",
    "\n",
    "Now that we have successfully ingested the GitHub repository and built our RAG pipeline, we need to tie everything together into a seamless user experience.\n",
    "\n",
    "\n",
    "\n",
    "We will create an interactive chat loop that continuously accepts developer input and executes our pipeline step-by-step:\n",
    "1. **Take Input:** Accept the user's message.\n",
    "2. **Determine Intent:** Pass the message through our local intent router (from Phase 2.1).\n",
    "3. **Handle Ambiguity:** If the intent is unclear, ask the user for clarification and skip the expensive search process.\n",
    "4. **Retrieve & Generate:** If the intent is clear, pass the question to our Retrieval Chain (from Phase 2.3) to search the database and generate an expert explanation."
   ],
   "id": "f31ff0dc8299cea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T16:41:42.009565Z",
     "start_time": "2026-02-21T15:25:58.113082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def codebuddy_chat():\n",
    "    print(\"=\"*50)\n",
    "    print(\"ü§ñ CodeBuddy: Your Open-Source Onboarder is Ready!\")\n",
    "    print(\"Type 'exit' or 'quit' to end the session.\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"\\nYou: \")\n",
    "\n",
    "        if user_query.lower() in ['exit', 'quit']:\n",
    "            print(\"CodeBuddy: Happy coding! See you next time.\")\n",
    "            break\n",
    "\n",
    "        if not user_query.strip():\n",
    "            continue\n",
    "\n",
    "        intent = process_user_input(user_query)\n",
    "\n",
    "        if intent is None or intent == \"AMBIGUOUS\":\n",
    "            continue\n",
    "\n",
    "        print(\"\\n[System Log] Searching repository and generating answer...\\n\")\n",
    "        try:\n",
    "            response = rag_chain.invoke({\"input\": user_query})\n",
    "            print(\"CodeBuddy:\")\n",
    "            print(response[\"answer\"])\n",
    "\n",
    "            sources = set([doc.metadata.get('source', 'Unknown File') for doc in response['context']])\n",
    "            print(\"\\nSources used:\")\n",
    "            for source in sources:\n",
    "                print(f\"- {source}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"CodeBuddy: Oops, something went wrong while searching the codebase. Error: {e}\")\n",
    "\n",
    "codebuddy_chat()"
   ],
   "id": "73b04bea150c70d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ü§ñ CodeBuddy: Your Open-Source Onboarder is Ready!\n",
      "Type 'exit' or 'quit' to end the session.\n",
      "==================================================\n",
      "User: which version of python to be used?\n",
      "[System Log] Intent Detected: PROJECT_SETUP (Confidence: 0.95)\n",
      "\n",
      "[System Log] Searching repository and generating answer...\n",
      "\n",
      "CodeBuddy:\n",
      "According to the context, Python 3.7 or higher is required for this repository reader.\n",
      "\n",
      "Sources used:\n",
      "- README.md\n",
      "User: which LLM model is used?\n",
      "[System Log] Intent Detected: CODE_EXPLANATION (Confidence: 0.99)\n",
      "\n",
      "[System Log] Searching repository and generating answer...\n",
      "\n",
      "CodeBuddy:\n",
      "I have the information you need.\n",
      "\n",
      "The LLM model used in this repository reader is OpenAI's GPT4, as mentioned in the provided context:\n",
      "\n",
      "[Langchain User Docs: Analysis of Twitter the-algorithm source code with LangChain, GPT4, and Deep Lake](https://python.langchain.com/docs/use_cases/code/twitter-the-algorithm-analysis-deeplake)\n",
      "\n",
      "So, the answer is OpenAI's GPT4.\n",
      "\n",
      "Sources used:\n",
      "- README.md\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 45\u001B[0m\n\u001B[1;32m     42\u001B[0m             \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCodeBuddy: Oops, something went wrong while searching the codebase. Error: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# Uncomment the line below to run the chat loop!\u001B[39;00m\n\u001B[0;32m---> 45\u001B[0m \u001B[43mcodebuddy_chat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[32], line 9\u001B[0m, in \u001B[0;36mcodebuddy_chat\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m50\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;66;03m# 1. Get User Input\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m     user_query \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43mYou: \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m user_query\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexit\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquit\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCodeBuddy: Happy coding! See you next time.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py:1282\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[0;34m(self, prompt)\u001B[0m\n\u001B[1;32m   1280\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[0;32m-> 1282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1286\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1287\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py:1325\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[0;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[1;32m   1322\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[1;32m   1323\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[1;32m   1324\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1325\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1326\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m   1327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dc59dce439247c59"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
