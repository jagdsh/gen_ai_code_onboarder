{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Phase 1: Introduction\n",
    "\n",
    "## 1.1 Background\n",
    "Open-source software (OSS) is the backbone of modern technology, driving innovation through community collaboration. A healthy open-source project relies on a continuous influx of new contributors to fix bugs, add features, and maintain the codebase. However, diving into an unfamiliar, complex repository is one of the most daunting tasks for any developer, whether they are junior programmers or seasoned veterans.\n",
    "\n",
    "## 1.2 Problem Statement\n",
    "Despite the desire to contribute to open-source, developers face a massive barrier to entry: **onboarding friction**. New contributors are often confronted with massive codebases, fragmented or outdated documentation, and complex architectural dependencies.\n",
    "\n",
    "Currently, a developer looking to contribute must spend hours or even days manually reading code, tracing functions, and deciphering the project's structure before writing a single line of code. This steep learning curve leads to developer frustration, abandoned pull requests, and a significant loss of potential talent for the open-source community.\n",
    "\n",
    "## 1.3 Solution & Approach\n",
    "To eliminate this onboarding friction, I'm building **CodeBuddy**, an AI-powered Open-Source Onboarder. CodeBuddy acts as an intelligent companion that guides developers through new codebases, explaining architecture, locating specific logic, and answering questions in real-time.\n",
    "\n",
    "***For assignment perspective I'm using local tech stack cannot ingest large repository yet. Once I'm able to mature it as agent running in a dedicated GPU can ingest large reposiroty***\n",
    "\n",
    "### Our Approach:\n",
    "I will tackle this problem by building a Retrieval-Augmented Generation (RAG) pipeline tailored for source code:\n",
    "1. **Data Ingestion & Parsing:** I will ingest the target open-source repository (code files, READMEs, and existing documentation) and parse the codebase into meaningful, logical chunks (e.g., functions, classes, and modules).\n",
    "2. **Embedding & Indexing:** These code chunks will be converted into vector embeddings and stored in a vector database, allowing for fast, semantic search capabilities.\n",
    "3. **Retrieval & Generation:** When a user asks a question (e.g., *\"Where is the database connection handled?\"* or *\"Explain how the authentication middleware works\"*), the system will retrieve the most relevant code snippets and pass them to an LLM to generate a clear, context-aware explanation.\n",
    "\n",
    "### Why Use Large Language Models (LLMs)?\n",
    "Using an LLM is the cornerstone of CodeBuddy because traditional search tools (like `grep` or IDE text search) are vastly insufficient for true code comprehension. I need LLMs for the following reasons:\n",
    "* **Semantic Code Understanding:** LLMs go beyond keyword matching; they understand the *intent* and logic behind the code, allowing them to explain complex algorithms in plain English.\n",
    "* **Contextual Synthesis:** An LLM can look at multiple retrieved files simultaneously and synthesize an answer that explains how different components of the repository interact with each other.\n",
    "* **Interactive Guidance:** LLMs allow developers to have a dynamic, conversational back-and-forth. If a developer doesn't understand an initial explanation, they can ask the LLM to simplify it, provide an example, or trace a specific variable's journey through the codebase."
   ],
   "id": "63680e85fca2e91d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Phase 2: System Design\n",
    "\n",
    "In this phase, we design the architecture of CodeBuddy. We will break this down step-by-step, starting with how the user interacts with the system and how the AI interprets their needs.\n",
    "\n",
    "## 2.1 Conversation Initialization & Intent Handling\n",
    "\n",
    "Before CodeBuddy can search the repository or explain code, it needs to establish a structured conversation with the user and accurately understand their goals. This interaction layer acts as the front door to our system.\n",
    "\n",
    "### Step 1: Start a Conversation (LLM Initialization)\n",
    "To initiate the conversation, we must instantiate the LLM with a specific \"System Prompt\" and memory management. This ensures the model behaves like an expert developer rather than a generic chatbot.\n",
    "\n",
    "* **System Prompting:** We define the LLM's persona, constraints, and instructions. For example: *\"You are CodeBuddy, an expert senior engineer. Your goal is to help a junior developer onboard onto a new open-source repository. Be concise, reference specific file paths when known, and do not make up code that does not exist.\"*\n",
    "* **Session Memory:** Because onboarding requires continuous dialogue, we must initialize a chat memory object (e.g., using LangChain's `ConversationBufferMemory`). This allows the LLM to remember previous questions and maintain context throughout the session.\n",
    "\n",
    "### Step 2: Get User Input (Intent Clarity & Confirmation)\n",
    "When a developer types a question, open-source repositories are often too large to simply search blindly. We need an intent routing mechanism to ensure we are retrieving the right kind of information.\n",
    "\n",
    "* **Capturing Input:** The system receives the user's raw query (e.g., *\"How do I start this?\"* or *\"Where is the auth logic?\"*).\n",
    "* **Intent Clarity (Classification):** Before querying our vector database, we pass the raw input through a lightweight LLM call (or a dedicated classifier) to determine the *intent* of the question. Common intents for CodeBuddy might include:\n",
    "    * `PROJECT_SETUP`: Questions about installation, Docker, or `npm install`.\n",
    "    * `ARCHITECTURE_OVERVIEW`: High-level questions about how services interact.\n",
    "    * `CODE_EXPLANATION`: Deep dives into specific functions or files.\n",
    "    * `CONTRIBUTION_GUIDELINES`: Questions about how to submit a PR or run tests.\n",
    "* **Intent Confirmation:** If a user's query is highly ambiguous (e.g., *\"Explain the user stuff\"*), the system pauses. Instead of running an expensive and likely inaccurate search, CodeBuddy replies with an **Intent Confirmation** prompt: *\"It sounds like you want to know about User Authentication and Authorization. Is that correct, or are you looking for the User UI components?\"* This human-in-the-loop step ensures high-accuracy retrieval later in the pipeline."
   ],
   "id": "e2d3a0222dc330fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.1.1 Implementation: Initialization and Intent Routing (Local Model)\n",
    "\n",
    "In the code block below, we set up the conversational interface entirely on our local machine. This ensures that repository code and developer queries remain completely private.\n",
    "\n",
    "\n",
    "\n",
    "This implementation handles:\n",
    "1. **Local LLM Setup:** We initialize a local model (e.g., `llama3.1` or `mistral`) using Ollama. We set the `format=\"json\"` parameter to guarantee the model outputs strictly parsable JSON for our routing logic.\n",
    "2. **Memory:** We instantiate a `ConversationBufferMemory` to keep track of the chat history.\n",
    "3. **Intent Classifier:** We define a specific prompt that forces the LLM to analyze the user's input and categorize it, outputting the result, a confidence score, and any clarifying questions."
   ],
   "id": "90f1c535cd18e05e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:04:04.856395Z",
     "start_time": "2026-02-21T11:04:01.064836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langsmith.env import get_git_info\n",
    "!pip install langchain langchain-ollama"
   ],
   "id": "42d8545119d0a39e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\r\n",
      "  Downloading langchain-1.2.10-py3-none-any.whl.metadata (5.7 kB)\r\n",
      "Collecting langchain-ollama\r\n",
      "  Downloading langchain_ollama-1.0.1-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting langchain-core<2.0.0,>=1.2.10 (from langchain)\r\n",
      "  Downloading langchain_core-1.2.14-py3-none-any.whl.metadata (4.4 kB)\r\n",
      "Collecting langgraph<1.1.0,>=1.0.8 (from langchain)\r\n",
      "  Downloading langgraph-1.0.9-py3-none-any.whl.metadata (7.4 kB)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain) (2.10.3)\r\n",
      "Collecting ollama<1.0.0,>=0.6.0 (from langchain-ollama)\r\n",
      "  Downloading ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (1.33)\r\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.2.10->langchain)\r\n",
      "  Downloading langsmith-0.7.6-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: packaging>=23.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (24.2)\r\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core<2.0.0,>=1.2.10->langchain)\r\n",
      "  Downloading pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.4 kB)\r\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.2.10->langchain)\r\n",
      "  Downloading tenacity-9.1.4-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (4.12.2)\r\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core<2.0.0,>=1.2.10->langchain)\r\n",
      "  Downloading uuid_utils-0.14.1-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (4.8 kB)\r\n",
      "Collecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.8->langchain)\r\n",
      "  Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.8 (from langgraph<1.1.0,>=1.0.8->langchain)\r\n",
      "  Downloading langgraph_prebuilt-1.0.8-py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph<1.1.0,>=1.0.8->langchain)\r\n",
      "  Downloading langgraph_sdk-0.3.8-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.8->langchain)\r\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: httpx>=0.27 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ollama<1.0.0,>=0.6.0->langchain-ollama) (0.28.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\r\n",
      "Requirement already satisfied: anyio in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (4.12.1)\r\n",
      "Requirement already satisfied: certifi in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (2025.4.26)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (3.7)\r\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (0.16.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/jags/miniconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain) (2.1)\r\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain)\r\n",
      "  Downloading ormsgpack-1.12.2-cp313-cp313-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (3.2 kB)\r\n",
      "Collecting orjson>=3.11.5 (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.8->langchain)\r\n",
      "  Downloading orjson-3.11.7-cp313-cp313-macosx_15_0_arm64.whl.metadata (41 kB)\r\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain)\r\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (2.32.3)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (0.23.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.10->langchain) (2.3.0)\r\n",
      "Downloading langchain-1.2.10-py3-none-any.whl (111 kB)\r\n",
      "Downloading langchain_ollama-1.0.1-py3-none-any.whl (29 kB)\r\n",
      "Downloading langchain_core-1.2.14-py3-none-any.whl (501 kB)\r\n",
      "Downloading langgraph-1.0.9-py3-none-any.whl (158 kB)\r\n",
      "Downloading ollama-0.6.1-py3-none-any.whl (14 kB)\r\n",
      "Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl (46 kB)\r\n",
      "Downloading langgraph_prebuilt-1.0.8-py3-none-any.whl (35 kB)\r\n",
      "Downloading langgraph_sdk-0.3.8-py3-none-any.whl (90 kB)\r\n",
      "Downloading langsmith-0.7.6-py3-none-any.whl (325 kB)\r\n",
      "Downloading pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\r\n",
      "Downloading tenacity-9.1.4-py3-none-any.whl (28 kB)\r\n",
      "Downloading uuid_utils-0.14.1-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (604 kB)\r\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m604.7/604.7 kB\u001B[0m \u001B[31m28.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\r\n",
      "Downloading orjson-3.11.7-cp313-cp313-macosx_15_0_arm64.whl (125 kB)\r\n",
      "Downloading ormsgpack-1.12.2-cp313-cp313-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (378 kB)\r\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\r\n",
      "Installing collected packages: xxhash, uuid-utils, tenacity, pyyaml, ormsgpack, orjson, requests-toolbelt, ollama, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-ollama, langgraph-prebuilt, langgraph, langchain\r\n",
      "Successfully installed langchain-1.2.10 langchain-core-1.2.14 langchain-ollama-1.0.1 langgraph-1.0.9 langgraph-checkpoint-4.0.0 langgraph-prebuilt-1.0.8 langgraph-sdk-0.3.8 langsmith-0.7.6 ollama-0.6.1 orjson-3.11.7 ormsgpack-1.12.2 pyyaml-6.0.3 requests-toolbelt-1.0.0 tenacity-9.1.4 uuid-utils-0.14.1 xxhash-3.6.0\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:05:40.619768Z",
     "start_time": "2026-02-21T11:05:40.559993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.memory import ConversationBufferMemory"
   ],
   "id": "908d9a487f0b4220",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T15:25:48.660679Z",
     "start_time": "2026-02-21T15:25:42.578846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0.2,\n",
    "    format=\"json\"\n",
    ")\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "intent_template = \"\"\"\n",
    "You are the routing engine for CodeBuddy, an AI assistant helping developers onboard onto an open-source codebase.\n",
    "Analyze the user's input and classify their intent into EXACTLY ONE of the following categories:\n",
    "- PROJECT_SETUP: Questions about installation, dependencies, Docker, etc.\n",
    "- ARCHITECTURE_OVERVIEW: Questions about folder structure, data flow, and architecture.\n",
    "- CODE_EXPLANATION: Questions about specific files, functions, or localized logic.\n",
    "- AMBIGUOUS: The request is too vague to search the codebase effectively.\n",
    "\n",
    "User Input: {user_input}\n",
    "\n",
    "Respond strictly in valid JSON format with the following schema:\n",
    "{{\n",
    "  \"intent\": \"CATEGORY\",\n",
    "  \"confidence\": 0.95,\n",
    "  \"clarifying_question\": \"Ask a question here ONLY if the intent is AMBIGUOUS, otherwise leave blank\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "intent_prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    template=intent_template\n",
    ")\n",
    "\n",
    "def process_user_input(user_query):\n",
    "    print(f\"User: {user_query}\")\n",
    "\n",
    "    formatted_prompt = intent_prompt.format(user_input=user_query)\n",
    "\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "\n",
    "    try:\n",
    "        raw_text = response.content if hasattr(response, \"content\") else response\n",
    "        classification = json.loads(raw_text)\n",
    "        intent = classification.get(\"intent\")\n",
    "        confidence = float(classification.get(\"confidence\", 0))\n",
    "\n",
    "        print(f\"[System Log] Intent Detected: {intent} (Confidence: {confidence})\")\n",
    "\n",
    "        if intent == \"AMBIGUOUS\" or confidence < 0.7:\n",
    "            clarification = classification.get(\"clarifying_question\", \"Could you please clarify what part of the project you are asking about?\")\n",
    "            print(f\"CodeBuddy: {clarification}\")\n",
    "            return None\n",
    "\n",
    "        return intent\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"[System Log] Error parsing intent. Asking user for clarification.\")\n",
    "        return \"AMBIGUOUS\"\n",
    "\n",
    "print(\"--- Test 1: Clear Intent ---\")\n",
    "intent_1 = process_user_input(\"How do I spin up the local Postgres database using Docker?\")\n",
    "\n",
    "print(\"\\n--- Test 2: Ambiguous Intent ---\")\n",
    "intent_2 = process_user_input(\"Explain the user stuff to me.\")"
   ],
   "id": "2629b5863933fddb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test 1: Clear Intent ---\n",
      "User: How do I spin up the local Postgres database using Docker?\n",
      "[System Log] Intent Detected: PROJECT_SETUP (Confidence: 0.95)\n",
      "\n",
      "--- Test 2: Ambiguous Intent ---\n",
      "User: Explain the user stuff to me.\n",
      "[System Log] Intent Detected: AMBIGUOUS (Confidence: 0.8)\n",
      "CodeBuddy: Can you please specify what 'user stuff' refers to? Are you asking about a particular file or functionality?\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2 Dynamic GitHub Ingestion and Vector Database\n",
    "\n",
    "For CodeBuddy to answer questions about a repository, it first needs to \"read\" and index the code. Instead of relying on local files, our system will prompt the user for a live GitHub URL and pull the code dynamically.\n",
    "\n",
    "\n",
    "This phase consists of three main steps:\n",
    "1. **Dynamic Loading:** We use Python's `input()` to grab the repository URL. Then, LangChain's `GitLoader` automatically clones it and loads its text files into memory.\n",
    "2. **Chunking (Code-Aware):** We split the files into smaller chunks using a Python-specific text splitter to ensure we don't accidentally slice functions or classes in half.\n",
    "3. **Embedding & Storage (ChromaDB):** We convert these text chunks into high-dimensional vector representations (embeddings) using our local Ollama model and store them in **Chroma** for semantic searching."
   ],
   "id": "b8313859e648cbd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T14:14:23.789605Z",
     "start_time": "2026-02-21T14:14:22.364871Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install GitPython chromadb langchain-community langchain-ollama",
   "id": "3e41cacbe588a826",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GitPython\r\n",
      "  Downloading gitpython-3.1.46-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: chromadb in /Users/jags/miniconda3/lib/python3.13/site-packages (1.5.1)\r\n",
      "Requirement already satisfied: langchain-community in /Users/jags/miniconda3/lib/python3.13/site-packages (0.4.1)\r\n",
      "Requirement already satisfied: langchain-ollama in /Users/jags/miniconda3/lib/python3.13/site-packages (1.0.1)\r\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython)\r\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.4.0)\r\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (2.10.3)\r\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.4.3)\r\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/jags/miniconda3/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.41.0)\r\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (2.3.3)\r\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (5.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (4.12.2)\r\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.24.2)\r\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (0.22.2)\r\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (0.51.1)\r\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (4.67.1)\r\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (7.7.0)\r\n",
      "Requirement already satisfied: importlib-resources in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (6.5.2)\r\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (1.78.1)\r\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (5.0.0)\r\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (0.24.0)\r\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (35.0.0)\r\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (9.1.4)\r\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (6.0.3)\r\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (5.2.0)\r\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (3.11.7)\r\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (0.28.1)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (13.9.4)\r\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from chromadb) (4.26.0)\r\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (1.2.14)\r\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (1.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (2.0.46)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (2.32.5)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (3.13.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (0.6.7)\r\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (2.13.1)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (0.7.6)\r\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-community) (0.4.3)\r\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-ollama) (0.6.1)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\r\n",
      "Requirement already satisfied: packaging>=24.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (24.2)\r\n",
      "Requirement already satisfied: pyproject_hooks in /Users/jags/miniconda3/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (1.2.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\r\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython)\r\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: anyio in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (4.12.1)\r\n",
      "Requirement already satisfied: certifi in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (3.7)\r\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/jags/miniconda3/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/jags/miniconda3/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\r\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/jags/miniconda3/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\r\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\r\n",
      "Requirement already satisfied: requests-oauthlib in /Users/jags/miniconda3/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\r\n",
      "Requirement already satisfied: urllib3!=2.6.0,>=1.24.2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\r\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/jags/miniconda3/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\r\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\r\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (0.14.1)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\r\n",
      "Requirement already satisfied: xxhash>=3.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.6.0)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\r\n",
      "Requirement already satisfied: flatbuffers in /Users/jags/miniconda3/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\r\n",
      "Requirement already satisfied: protobuf in /Users/jags/miniconda3/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.5)\r\n",
      "Requirement already satisfied: sympy in /Users/jags/miniconda3/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\r\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/jags/miniconda3/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\r\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\r\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic>=1.9->chromadb) (2.27.1)\r\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.3.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (2.2.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\r\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /Users/jags/miniconda3/lib/python3.13/site-packages (from tokenizers>=0.13.2->chromadb) (1.4.1)\r\n",
      "Requirement already satisfied: click>=8.2.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (8.3.1)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\r\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (0.0.4)\r\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/jags/miniconda3/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\r\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\r\n",
      "Requirement already satisfied: watchfiles>=0.20 in /Users/jags/miniconda3/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/jags/miniconda3/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (16.0)\r\n",
      "Requirement already satisfied: filelock in /Users/jags/miniconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.24.3)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2026.2.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\r\n",
      "Requirement already satisfied: typer-slim in /Users/jags/miniconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (0.24.0)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/jags/miniconda3/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/jags/miniconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (2.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\r\n",
      "Downloading gitpython-3.1.46-py3-none-any.whl (208 kB)\r\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\r\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\r\n",
      "Installing collected packages: smmap, gitdb, GitPython\r\n",
      "Successfully installed GitPython-3.1.46 gitdb-4.0.12 smmap-5.0.2\r\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T14:14:28.878213Z",
     "start_time": "2026-02-21T14:14:28.021532Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -U langchain-ollama",
   "id": "d1c84a1fd7b39c72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in /Users/jags/miniconda3/lib/python3.13/site-packages (1.0.1)\r\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-ollama) (1.2.14)\r\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.6.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-ollama) (0.6.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.33)\r\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.7.6)\r\n",
      "Requirement already satisfied: packaging>=23.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (24.2)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.10.3)\r\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (6.0.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (9.1.4)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (4.12.2)\r\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.14.1)\r\n",
      "Requirement already satisfied: httpx>=0.27 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ollama<1.0.0,>=0.6.0->langchain-ollama) (0.28.1)\r\n",
      "Requirement already satisfied: anyio in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (4.12.1)\r\n",
      "Requirement already satisfied: certifi in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (2025.4.26)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (3.7)\r\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jags/miniconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.6.0->langchain-ollama) (0.16.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/jags/miniconda3/lib/python3.13/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.1)\r\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.11.7)\r\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (1.0.0)\r\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.32.5)\r\n",
      "Requirement already satisfied: xxhash>=3.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.6.0)\r\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.23.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.27.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain-ollama) (2.3.0)\r\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T16:46:40.180096Z",
     "start_time": "2026-02-21T16:46:40.175185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "from langchain_community.document_loaders import GitLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, Language\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import chromadb\n",
    "import chromadb.config"
   ],
   "id": "55927fd99c34f247",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T10:48:59.155971Z",
     "start_time": "2026-02-22T10:48:50.098951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"=\"*50)\n",
    "print(\"üì• CodeBuddy Repository Ingestion\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def get_git_info():\n",
    "    github_url = input(\"Enter the GitHub Repository URL to ingest (e.g., https://github.com/hwchase17/langchain-tiny): \").strip()\n",
    "\n",
    "    if not github_url:\n",
    "        github_url = \"https://github.com/bhagirathbhard/langchain-reporead\"\n",
    "        print(f\"\\n[System Log] No URL provided. Defaulting to: {github_url}\")\n",
    "\n",
    "    repo_destination = \"./cloned_repo\"\n",
    "    db_dir = \"./chroma_db\"\n",
    "\n",
    "    if os.path.exists(repo_destination):\n",
    "        print(f\"\\n[System Log] Clearing previous repository data at {repo_destination}...\")\n",
    "        shutil.rmtree(repo_destination)\n",
    "\n",
    "\n",
    "    print(f\"\\n[System Log] Cloning and loading documents from {github_url}...\")\n",
    "\n",
    "    loader = GitLoader(\n",
    "        clone_url=github_url,\n",
    "        repo_path=repo_destination,\n",
    "        branch=\"main\",\n",
    "        file_filter=lambda file_path: file_path.endswith(\".py\") or file_path.endswith(\".md\")\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "    print(f\"[System Log] Successfully loaded {len(documents)} file(s) from GitHub.\")\n",
    "\n",
    "    print(\"\\n[System Log] Splitting code into semantic chunks...\")\n",
    "    python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "        language=Language.PYTHON,\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    chunks = python_splitter.split_documents(documents)\n",
    "    print(f\"[System Log] Created {len(chunks)} chunk(s).\")\n",
    "\n",
    "    print(\"\\n[System Log] Generating embeddings and storing in local ChromaDB...\")\n",
    "\n",
    "    embeddings = OllamaEmbeddings(model=\"llama3.1\")\n",
    "\n",
    "    vector_db = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=db_dir\n",
    "    )\n",
    "\n",
    "    print(\"\\n[System Log] ‚úÖ GitHub Ingestion complete! CodeBuddy's knowledge base is ready.\")\n",
    "\n",
    "get_git_info()"
   ],
   "id": "5c8ad7c5b6c2071b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üì• CodeBuddy Repository Ingestion\n",
      "==================================================\n",
      "\n",
      "[System Log] Cloning and loading documents from https://github.com/bhagirathbhard/langchain-reporead...\n",
      "[System Log] Successfully loaded 1 file(s) from GitHub.\n",
      "\n",
      "[System Log] Splitting code into semantic chunks...\n",
      "[System Log] Created 4 chunk(s).\n",
      "\n",
      "[System Log] Generating embeddings and storing in local ChromaDB...\n",
      "\n",
      "[System Log] ‚úÖ GitHub Ingestion complete! CodeBuddy's knowledge base is ready.\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.3 Retrieval and Answer Generation\n",
    "\n",
    "The final step in our RAG pipeline is taking the user's question, finding the relevant code we just pulled from GitHub, and letting the LLM explain it.\n",
    "\n",
    "[Image of a Retrieval-Augmented Generation system querying a vector database]\n",
    "\n",
    "This phase works by chaining together a few core components:\n",
    "1. **The Retriever:** We convert our ChromaDB into a \"Retriever\" object. When given a query, it will search the database and return the top `k` most semantically similar code chunks from the GitHub repository.\n",
    "2. **The Prompt Template:** We define CodeBuddy's persona and provide a strict instruction to *only* use the retrieved context to answer the question, preventing the model from hallucinating code that doesn't exist.\n",
    "3. **The Document Chain (`create_stuff_documents_chain`):** This LangChain utility takes the retrieved code chunks and \"stuffs\" them into the `{context}` variable of our prompt.\n",
    "4. **The Retrieval Chain (`create_retrieval_chain`):** This acts as the orchestrator. It takes the user's input, hits the retriever, passes the documents to the document chain, and returns the final LLM-generated answer."
   ],
   "id": "8417833e8c937847"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T14:17:22.604956Z",
     "start_time": "2026-02-21T14:17:22.590775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n"
   ],
   "id": "c0dfa1b0c42dabfb",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T14:17:26.532556Z",
     "start_time": "2026-02-21T14:17:23.892498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = OllamaLLM(model=\"llama3.1\", temperature=0.3)\n",
    "\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are CodeBuddy, an expert senior engineer helping a junior developer onboard onto a new open-source codebase. \"\n",
    "    \"Use the following pieces of retrieved code context to answer the user's question. \"\n",
    "    \"If you don't know the answer or the context doesn't contain the right code, just clearly say that you don't know. \"\n",
    "    \"Do not make up code or file names. Keep your explanations clear, concise, and structured.\\n\\n\"\n",
    "    \"Context:\\n{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "print(\"--- Testing CodeBuddy Answer Generation ---\")\n",
    "\n",
    "test_question = \"Based on the repository, what is the main purpose of this project?\"\n",
    "print(f\"User: {test_question}\\n\")\n",
    "\n",
    "response = rag_chain.invoke({\"input\": test_question})\n",
    "\n",
    "print(\"CodeBuddy:\")\n",
    "print(response[\"answer\"])\n",
    "\n",
    "print(\"\\n---\")\n",
    "print(f\"[System Log] Answer generated using {len(response['context'])} retrieved source chunks.\")"
   ],
   "id": "ae14bd4f66cfa6c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing CodeBuddy Answer Generation ---\n",
      "User: Based on the repository, what is the main purpose of this project?\n",
      "\n",
      "CodeBuddy:\n",
      "The main purpose of this project is to provide a set of tools and scripts that leverage Langchain and OpenAI to read and analyze the content of a repository. It allows users to ask questions about a repository by storing them in a `questions.txt` file, and then generates individual answers in markdown files within an `answers` folder using the output from the LLM (Large Language Model).\n",
      "\n",
      "---\n",
      "[System Log] Answer generated using 4 retrieved source chunks.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.4 Agentic Extension: Function Calling (Tool Use)\n",
    "\n",
    "RAG pipelines are excellent for answering questions about static code logic, but open-source repositories are dynamic. If a developer asks, *\"What are the latest open issues? Has someone raised a PR for this?\"*, a static vector database cannot help them.\n",
    "\n",
    "To solve this, we are upgrading CodeBuddy into an **Agent**. By implementing **Tool Calling**, we give our local LLM the autonomy to execute real Python functions‚Äîlike making live API calls to GitHub‚Äîwhenever it detects that the user needs live data.\n",
    "\n",
    "### The Approach:\n",
    "1. **The Tool (`@tool`):** We define a Python function that requests the latest issues from the GitHub API. We programmatically distinguish between standard issues and Pull Requests (GitHub returns both in the same endpoint).\n",
    "2. **The Chat Model (`ChatOllama`):** We use a model class that supports the `.bind_tools()` method.\n",
    "3. **The Agent Executor:** We use LangChain's `create_tool_calling_agent` to create a loop where the LLM can \"think,\" decide to use the GitHub tool, wait for the Python script to fetch the JSON data, and finally summarize the live results for the user."
   ],
   "id": "1f1e9bdd3460c2eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:30.217551Z",
     "start_time": "2026-02-23T08:05:28.723549Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install requests",
   "id": "127b8d7f7fdd2b96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/jags/miniconda3/lib/python3.13/site-packages (2.32.5)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jags/miniconda3/lib/python3.13/site-packages (from requests) (2025.4.26)\r\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:06:43.156725Z",
     "start_time": "2026-02-23T08:06:37.110496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from langchain_core.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"üîå Upgrading CodeBuddy with GitHub API Tools\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "@tool\n",
    "def check_github_issues(repo_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the latest open issues and checks if any Pull Requests have been raised for a given GitHub repository URL.\n",
    "    Args:\n",
    "        repo_url: The full GitHub repository URL (e.g., \"https://github.com/hwchase17/langchain-tiny\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parts = repo_url.rstrip('/').split('/')\n",
    "        owner, repo = parts[-2], parts[-1]\n",
    "\n",
    "        api_url = f\"https://api.github.com/repos/{owner}/{repo}/issues?state=open&per_page=5\"\n",
    "\n",
    "        headers = {\"Accept\": \"application/vnd.github.v3+json\"}\n",
    "        response = requests.get(api_url, headers=headers)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            return f\"GitHub API error: Status {response.status_code}. (You might be rate limited)\"\n",
    "\n",
    "        issues_data = response.json()\n",
    "\n",
    "        if not issues_data:\n",
    "            return \"There are no open issues or PRs for this repository right now.\"\n",
    "\n",
    "        summary = [\"Here are the latest 5 open items from the repository:\\n\"]\n",
    "        for item in issues_data:\n",
    "            number = item.get(\"number\")\n",
    "            title = item.get(\"title\")\n",
    "\n",
    "            is_pr = \"pull_request\" in item\n",
    "            item_type = \"Pull Request\" if is_pr else \"Issue\"\n",
    "\n",
    "            summary.append(f\"- [{item_type} #{number}] {title}\")\n",
    "\n",
    "        return \"\\n\".join(summary)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Tool error fetching issues: {str(e)}\"\n",
    "\n",
    "chat_model = ChatOllama(model=\"llama3.1\", temperature=0.1)\n",
    "\n",
    "tools = [check_github_issues]\n",
    "\n",
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are CodeBuddy, an expert developer assistant. Use the provided tools to answer the user's questions. Summarize the tool's raw output nicely for the user.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "agent = create_tool_calling_agent(chat_model, tools, agent_prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "print(\"\\n[System Log] Asking CodeBuddy to check live issues...\\n\")\n",
    "\n",
    "test_query = f\"Can you check the latest issues for {GITHUB_URL} and tell me if there are any Pull Requests?\"\n",
    "print(f\"üë§ You: {test_query}\\n\")\n",
    "\n",
    "response = agent_executor.invoke({\"input\": test_query})\n",
    "\n",
    "print(\"\\nü§ñ CodeBuddy:\")\n",
    "print(response[\"output\"])"
   ],
   "id": "d1acfcfa7d8f80f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "üîå Upgrading CodeBuddy with GitHub API Tools\n",
      "==================================================\n",
      "\n",
      "[System Log] Asking CodeBuddy to check live issues...\n",
      "\n",
      "üë§ You: Can you check the latest issues for https://github.com/bhagirathbhard/langchain-reporead and tell me if there are any Pull Requests?\n",
      "\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `check_github_issues` with `{'repo_url': 'https://github.com/bhagirathbhard/langchain-reporead'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3mThere are no open issues or PRs for this repository right now.\u001B[0m\u001B[32;1m\u001B[1;3m<|python_tag|>{\"name\": \"check_github_issues\", \"parameters\": {\"repo_url\":\"https://github.com/bhagirathbhard/langchain-reporead\"}}\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "ü§ñ CodeBuddy:\n",
      "<|python_tag|>{\"name\": \"check_github_issues\", \"parameters\": {\"repo_url\":\"https://github.com/bhagirathbhard/langchain-reporead\"}}\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Phase 3: Bringing It All Together (Unified RAG + Agent UI)\n",
    "\n",
    "In this final phase, we combine all our system components into a single interactive chat interface.\n",
    "\n",
    "CodeBuddy now has a \"split-brain\" architecture:\n",
    "1. **The Router:** When a user asks a question, the LLM first classifies the intent.\n",
    "2. **The RAG Path (`rag_chain`):** If the user asks about code logic or architecture, the system queries the local Chroma vector database.\n",
    "3. **The Agent Path (`agent_executor`):** If the user asks about live PRs or open issues, the system bypasses the database and triggers the GitHub API tool to fetch real-time data.\n",
    "4. **The UI:** Everything is wrapped in a clean, inline `ipywidgets` interface to prevent IDE popups and maintain chat history."
   ],
   "id": "f31ff0dc8299cea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T10:51:35.340295Z",
     "start_time": "2026-02-22T10:51:33.109805Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install ipywidgets",
   "id": "377b5dfcbdff3840",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\r\n",
      "  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Collecting comm>=0.1.3 (from ipywidgets)\r\n",
      "  Downloading comm-0.2.3-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ipywidgets) (9.9.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ipywidgets) (5.14.3)\r\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\r\n",
      "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\r\n",
      "  Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: decorator>=4.3.2 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\r\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.18.1 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\r\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\r\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\r\n",
      "Requirement already satisfied: pygments>=2.11.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\r\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/jags/miniconda3/lib/python3.13/site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/jags/miniconda3/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /Users/jags/miniconda3/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/jags/miniconda3/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.1)\r\n",
      "Requirement already satisfied: pure-eval in /Users/jags/miniconda3/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\r\n",
      "Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\r\n",
      "Downloading comm-0.2.3-py3-none-any.whl (7.3 kB)\r\n",
      "Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\r\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m914.9/914.9 kB\u001B[0m \u001B[31m25.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\r\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m44.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, comm, ipywidgets\r\n",
      "Successfully installed comm-0.2.3 ipywidgets-8.1.8 jupyterlab_widgets-3.0.16 widgetsnbextension-4.0.15\r\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:13:23.607641Z",
     "start_time": "2026-02-23T08:13:23.572517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üöÄ Compiling Final CodeBuddy Interface...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "updated_intent_template = \"\"\"\n",
    "You are the routing engine for CodeBuddy. Analyze the user's input and classify their intent into EXACTLY ONE of the following categories:\n",
    "- PROJECT_SETUP: Questions about installation or dependencies.\n",
    "- ARCHITECTURE_OVERVIEW: Questions about folder structure and data flow.\n",
    "- CODE_EXPLANATION: Questions about specific files or code logic.\n",
    "- LIVE_ISSUES: Questions about open issues, pull requests, or repository status.\n",
    "- AMBIGUOUS: The request is too vague.\n",
    "\n",
    "User Input: {user_input}\n",
    "\n",
    "Respond strictly in valid JSON format:\n",
    "{{\"intent\": \"CATEGORY\", \"confidence\": 0.95, \"clarifying_question\": \"Only if AMBIGUOUS\"}}\n",
    "\"\"\"\n",
    "updated_intent_prompt = PromptTemplate(input_variables=[\"user_input\"], template=updated_intent_template)\n",
    "\n",
    "def get_intent(user_query):\n",
    "    formatted_prompt = updated_intent_prompt.format(user_input=user_query)\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "    raw_text = response.content if hasattr(response, \"content\") else response\n",
    "    try:\n",
    "        return json.loads(raw_text).get(\"intent\", \"AMBIGUOUS\")\n",
    "    except:\n",
    "        return \"AMBIGUOUS\"\n",
    "\n",
    "\n",
    "output_area = widgets.Output(layout={'border': '1px solid #ccc', 'padding': '10px'})\n",
    "text_input = widgets.Text(\n",
    "    placeholder='Ask about the code or live issues/PRs...',\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "submit_button = widgets.Button(\n",
    "    description='Send',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='15%')\n",
    ")\n",
    "input_box = widgets.HBox([text_input, submit_button])\n",
    "\n",
    "with output_area:\n",
    "    print(\"ü§ñ CodeBuddy: Your Unified Open-Source Onboarder is Ready!\")\n",
    "    print(f\"üîó Connected to: {GITHUB_URL}\")\n",
    "    print(\"Type 'exit' or 'quit' to end the session.\\n\" + \"-\"*60)\n",
    "\n",
    "def handle_interaction(button_click=None):\n",
    "    user_query = text_input.value\n",
    "    if not user_query.strip(): return\n",
    "    text_input.value = ''\n",
    "\n",
    "    if user_query.lower() in ['exit', 'quit']:\n",
    "        with output_area:\n",
    "            print(\"\\nü§ñ CodeBuddy: Chat closed. Happy coding!\")\n",
    "        input_box.close()\n",
    "        return\n",
    "\n",
    "    with output_area:\n",
    "        print(f\"\\nüë§ You: {user_query}\")\n",
    "\n",
    "\n",
    "        intent = get_intent(user_query)\n",
    "        print(f\"   [System Log] Intent routed to: {intent}\")\n",
    "\n",
    "        if intent == \"AMBIGUOUS\":\n",
    "            print(\"ü§ñ CodeBuddy: Could you please clarify what part of the project you are asking about?\")\n",
    "\n",
    "        elif intent == \"LIVE_ISSUES\":\n",
    "            print(\"   [System Log] Triggering GitHub Agent...\\n\")\n",
    "            try:\n",
    "                response = agent_executor.invoke({\"input\": user_query})\n",
    "                print(\"ü§ñ CodeBuddy:\")\n",
    "                print(response[\"output\"])\n",
    "            except Exception as e:\n",
    "                print(f\"ü§ñ CodeBuddy: Error fetching live data: {e}\")\n",
    "\n",
    "        else:\n",
    "            print(\"   [System Log] Searching local vector database...\\n\")\n",
    "            try:\n",
    "                response = rag_chain.invoke({\"input\": user_query})\n",
    "                print(\"ü§ñ CodeBuddy:\")\n",
    "                print(response[\"answer\"])\n",
    "\n",
    "                sources = set([doc.metadata.get('source', 'Unknown') for doc in response['context']])\n",
    "                print(\"\\nüìÇ Sources referenced:\")\n",
    "                for source in sources: print(f\"  - {source}\")\n",
    "            except Exception as e:\n",
    "                print(f\"ü§ñ CodeBuddy: Error searching codebase: {e}\")\n",
    "\n",
    "submit_button.on_click(handle_interaction)\n",
    "text_input.on_submit(handle_interaction)\n",
    "display(output_area, input_box)"
   ],
   "id": "7f88216c89232a73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ Compiling Final CodeBuddy Interface...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gv/vp9gzv0530z5gsl8qdmlmvm00000gn/T/ipykernel_36945/2853798692.py:103: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  text_input.on_submit(handle_interaction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid #ccc', border_left='1px solid #ccc', border_right='1px solid #cc‚Ä¶"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "029e9fe6aff243dcab6de2afeb1e9a0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(Text(value='', layout=Layout(width='80%'), placeholder='Ask about the code or live issues/PRs..‚Ä¶"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "939ec8a30eed458cb0fc11d6c3a24383"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dc59dce439247c59"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
